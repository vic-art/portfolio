{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba410a97-43cd-4e97-a8e1-4f00be9aa23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/artem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/artem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Basic libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#Visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#NLTK libraries\n",
    "import nltk\n",
    "import string\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Machine Learning libraries\n",
    "import sklearn \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Metrics libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306ce7d9-cbb3-470d-83cf-fef6a2aceafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "\n",
    "import umap.umap_ as umap\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f196ae26-d9f4-4c08-ab97-a3e6de12bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_tree = pd.read_csv('categories_tree.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7851260-9bb7-40d4-9f55-557e4e1c8bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Все категории</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>Урбеч</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>Варенье и джемы</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>Сухие завтраки</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>Масла</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id            title  parent_id\n",
       "0    1    Все категории          0\n",
       "1  114            Урбеч       1913\n",
       "2  115  Варенье и джемы        328\n",
       "3  128   Сухие завтраки       2475\n",
       "4  131            Масла       2475"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories_tree.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efc8847-e793-4b27-9802-361a1d48e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('train.parquet')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267142c8-4084-411d-aa27-6dd754cb5658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>short_description</th>\n",
       "      <th>name_value_characteristics</th>\n",
       "      <th>rating</th>\n",
       "      <th>feedback_quantity</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1267423</td>\n",
       "      <td>Muhle Manikure Песочные колпачки для педикюра ...</td>\n",
       "      <td>Muhle Manikure Колпачок песочный шлифовальный ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128833</td>\n",
       "      <td>Sony Xperia L1 Защитное стекло 2,5D</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>13408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569924</td>\n",
       "      <td>Конверт для денег Прекрасная роза, 16,5 х 8 см</td>\n",
       "      <td>Конверт для денег «Прекрасная роза», 16,5 × 8 см</td>\n",
       "      <td>None</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1264824</td>\n",
       "      <td>Серьги</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1339052</td>\n",
       "      <td>Наклейки на унитаз для туалета на крышку бачок...</td>\n",
       "      <td>Водостойкая, интересная наклейка на унитаз раз...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1267423  Muhle Manikure Песочные колпачки для педикюра ...   \n",
       "1   128833                Sony Xperia L1 Защитное стекло 2,5D   \n",
       "2   569924     Конверт для денег Прекрасная роза, 16,5 х 8 см   \n",
       "3  1264824                                             Серьги   \n",
       "4  1339052  Наклейки на унитаз для туалета на крышку бачок...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Muhle Manikure Колпачок песочный шлифовальный ...   \n",
       "1                                               None   \n",
       "2   Конверт для денег «Прекрасная роза», 16,5 × 8 см   \n",
       "3                                               None   \n",
       "4  Водостойкая, интересная наклейка на унитаз раз...   \n",
       "\n",
       "  name_value_characteristics    rating  feedback_quantity  category_id  \n",
       "0                       None  0.000000                  0         2693  \n",
       "1                       None  4.666667                  9        13408  \n",
       "2                       None  5.000000                  6        11790  \n",
       "3                       None  0.000000                  0        14076  \n",
       "4                       None  0.000000                  0        12401  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11187095-89c8-4519-9b3f-2b94e6a28740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c007a340-8a90-4652-9dc6-c54eb0f58e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>short_description</th>\n",
       "      <th>name_value_characteristics</th>\n",
       "      <th>rating</th>\n",
       "      <th>feedback_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070974</td>\n",
       "      <td>Браслет из натуральных камней LOTUS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450413</td>\n",
       "      <td>Fusion Life - Шампунь для сухих и окрашенных в...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126857</td>\n",
       "      <td>Микрофон для ПК jack 3,5мм всенаправленный</td>\n",
       "      <td>универсальный 3,5 мм микрофон запишет ваш звук</td>\n",
       "      <td>None</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577569</td>\n",
       "      <td>Серьги гвоздики сердце</td>\n",
       "      <td>Серьги гвоздики сердце</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>869328</td>\n",
       "      <td>Чёрно-красная стильная брошь \"Тюльпаны\" из акр...</td>\n",
       "      <td>Стильная и яркая брошь ручной работы! Великоле...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1070974                Браслет из натуральных камней LOTUS   \n",
       "1   450413  Fusion Life - Шампунь для сухих и окрашенных в...   \n",
       "2   126857         Микрофон для ПК jack 3,5мм всенаправленный   \n",
       "3  1577569                             Серьги гвоздики сердце   \n",
       "4   869328  Чёрно-красная стильная брошь \"Тюльпаны\" из акр...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2     универсальный 3,5 мм микрофон запишет ваш звук   \n",
       "3                             Серьги гвоздики сердце   \n",
       "4  Стильная и яркая брошь ручной работы! Великоле...   \n",
       "\n",
       "  name_value_characteristics    rating  feedback_quantity  \n",
       "0                       None  0.000000                  0  \n",
       "1                       None  4.333333                  6  \n",
       "2                       None  3.708333                 24  \n",
       "3                       None  0.000000                  0  \n",
       "4                       None  0.000000                  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2cb89b3-9196-4fa3-b081-c23e6b64058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283452 entries, 0 to 283451\n",
      "Data columns (total 7 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   id                          283452 non-null  int64  \n",
      " 1   title                       283452 non-null  object \n",
      " 2   short_description           133130 non-null  object \n",
      " 3   name_value_characteristics  50360 non-null   object \n",
      " 4   rating                      283452 non-null  float64\n",
      " 5   feedback_quantity           283452 non-null  int64  \n",
      " 6   category_id                 283452 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 15.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d43930-1738-49f7-a4a2-1120ad52ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70864 entries, 0 to 70863\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          70864 non-null  int64  \n",
      " 1   title                       70864 non-null  object \n",
      " 2   short_description           33346 non-null  object \n",
      " 3   name_value_characteristics  12576 non-null  object \n",
      " 4   rating                      70864 non-null  float64\n",
      " 5   feedback_quantity           70864 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ba7df9-877b-4e53-b1ee-1df0dae42095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                 0\n",
       "title                              0\n",
       "short_description             150322\n",
       "name_value_characteristics    233092\n",
       "rating                             0\n",
       "feedback_quantity                  0\n",
       "category_id                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the null in data\n",
    "df_train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41abf23-bf44-42d4-a16f-16aa439136fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                0\n",
       "title                             0\n",
       "short_description             37518\n",
       "name_value_characteristics    58288\n",
       "rating                            0\n",
       "feedback_quantity                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1cf77f3-3820-4653-9196-805448d7f6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['category_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618a333e-310c-4b94-83c7-00016ac452c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11937    14967\n",
       "13408     7153\n",
       "13061     6434\n",
       "13143     6145\n",
       "13253     3390\n",
       "         ...  \n",
       "13756        2\n",
       "13007        2\n",
       "2598         2\n",
       "11917        2\n",
       "13787        2\n",
       "Name: category_id, Length: 1231, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['category_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27453e94-f6a8-428a-bf91-dba9c4939b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ids_list = sorted(list(set(df_train['category_id'])))\n",
    "df_train['category_id_label'] = df_train['category_id'].apply(lambda cat_id: cat_ids_list.index(cat_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c70363-6f6c-4033-9262-ea711948b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2693"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ids_list[36]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec3cce5-c8b5-4127-b1f8-f9dac8917870",
   "metadata": {},
   "source": [
    "# Extract all root-to-leaf paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5005fc-e1aa-4ef9-8390-80114ebde20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# build the graph\n",
    "G = nx.from_pandas_edgelist(df_categories_tree, source='parent_id', target='id',\n",
    "                            create_using=nx.DiGraph)\n",
    "# map id to name\n",
    "node_names = df_categories_tree.set_index('id')['title'].to_dict()\n",
    "\n",
    "# get path from root (0) to the node\n",
    "def get_path(node):\n",
    "    # this is a tree, so exactly one simple path for each node\n",
    "    for path in nx.simple_paths.all_simple_paths(G, 0, node):\n",
    "        return [node_names.get(i) for i in path[1:]]\n",
    "\n",
    "df_categories_tree['path'] = df_categories_tree['id'].apply(get_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a66d690-47aa-4bc1-914b-cdb8f9e57453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a526192a-7af6-454e-b05a-50eabd491bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_categories_tree[['id','path']], how = 'left', \n",
    "         left_on = 'category_id', right_on = 'id').drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c5f0aba-41e4-49b5-868f-01564b195a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>short_description</th>\n",
       "      <th>name_value_characteristics</th>\n",
       "      <th>rating</th>\n",
       "      <th>feedback_quantity</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_id_label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muhle Manikure Песочные колпачки для педикюра ...</td>\n",
       "      <td>Muhle Manikure Колпачок песочный шлифовальный ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2693</td>\n",
       "      <td>36</td>\n",
       "      <td>[Все категории, Красота, Маникюр и педикюр, Ин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sony Xperia L1 Защитное стекло 2,5D</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>13408</td>\n",
       "      <td>856</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Конверт для денег Прекрасная роза, 16,5 х 8 см</td>\n",
       "      <td>Конверт для денег «Прекрасная роза», 16,5 × 8 см</td>\n",
       "      <td>None</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>11790</td>\n",
       "      <td>207</td>\n",
       "      <td>[Все категории, Товары для дома, Товары для пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Серьги</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>1116</td>\n",
       "      <td>[Все категории, Аксессуары, Женские аксессуары...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Наклейки на унитаз для туалета на крышку бачок...</td>\n",
       "      <td>Водостойкая, интересная наклейка на унитаз раз...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12401</td>\n",
       "      <td>460</td>\n",
       "      <td>[Все категории, Товары для дома, Декор и интер...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Muhle Manikure Песочные колпачки для педикюра ...   \n",
       "1                Sony Xperia L1 Защитное стекло 2,5D   \n",
       "2     Конверт для денег Прекрасная роза, 16,5 х 8 см   \n",
       "3                                             Серьги   \n",
       "4  Наклейки на унитаз для туалета на крышку бачок...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Muhle Manikure Колпачок песочный шлифовальный ...   \n",
       "1                                               None   \n",
       "2   Конверт для денег «Прекрасная роза», 16,5 × 8 см   \n",
       "3                                               None   \n",
       "4  Водостойкая, интересная наклейка на унитаз раз...   \n",
       "\n",
       "  name_value_characteristics    rating  feedback_quantity  category_id  \\\n",
       "0                       None  0.000000                  0         2693   \n",
       "1                       None  4.666667                  9        13408   \n",
       "2                       None  5.000000                  6        11790   \n",
       "3                       None  0.000000                  0        14076   \n",
       "4                       None  0.000000                  0        12401   \n",
       "\n",
       "   category_id_label                                               path  \n",
       "0                 36  [Все категории, Красота, Маникюр и педикюр, Ин...  \n",
       "1                856  [Все категории, Электроника, Смартфоны и телеф...  \n",
       "2                207  [Все категории, Товары для дома, Товары для пр...  \n",
       "3               1116  [Все категории, Аксессуары, Женские аксессуары...  \n",
       "4                460  [Все категории, Товары для дома, Декор и интер...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef10b92f-7b8a-4dd0-9551-1ce45612578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['short_description'] = df_train['short_description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67425c0f-8cd1-4d7e-8c88-6b66e3e4f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate title and short_description columns \n",
    "df_train['title+short_description'] = df_train['title'] + \" \" + df_train['short_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9239362-4791-4ea7-9c7d-3bec08aa7e4c",
   "metadata": {},
   "source": [
    "# Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991c8f73-2dc2-49db-b211-d957af911cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['title+short_description']\n",
    "y = df_train['category_id_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e707edf-1152-4f73-a0cd-882eb6833a91",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8a299d1-e5d9-4de3-84bc-57fb5f793a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12207f3-5324-4d50-beaa-02a422dfe325",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d46d68-4c72-43d1-b845-363964b6cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing Punctuation\n",
    "    text_p = text.translate(str.maketrans('', '', string.punctuation + '«»'))\n",
    "    \n",
    "    return text_p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa4ced57-69ef-4092-af06-b19fb2300d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = X_train.apply(preprocess)\n",
    "X_val_preprocessed = X_val.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fdfca-dc54-4962-ad4f-c2c4f136421d",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8f9bc64-9535-4a83-b74a-6c55157a4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorization = TfidfVectorizer()\n",
    "X_train_tfidf = vectorization.fit_transform(X_train_preprocessed)\n",
    "X_val_tfidf = vectorization.transform(X_val_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e5016-2597-40a4-9c70-1c7332dea7fa",
   "metadata": {},
   "source": [
    "# LogisticRegression (multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f5a3c49-ea67-46ec-a98c-8f0b1b37ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 25 epochs took 590 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', solver='saga',\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(solver='saga', multi_class='multinomial',verbose=10, max_iter=1000)\n",
    "log.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b94c6d1-7442-4af3-8610-3a072692d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "filename = 'log_reg_model1.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ae856-f246-4ed7-b8d1-88ce13afc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(log, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3c454-3194-46d5-8510-443219d1576b",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c2f03a7-7f67-4a7c-8b44-ae0b6e03a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42b8e14d-00ba-455e-a74f-93e488de179e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_labels = loaded_model.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29e8e964-408f-44bb-9c13-48970aec87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for label in preds_labels:\n",
    "    preds.append(cat_ids_list[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d50ff33-757a-4366-a383-893064eb5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_cat = []\n",
    "for i in y_val:\n",
    "    y_val_cat.append(cat_ids_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc5e3ec3-162e-4c27-85f0-cc61bf595164",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2598       0.00      0.00      0.00         1\n",
      "        2599       0.93      0.99      0.96        77\n",
      "        2600       1.00      0.70      0.82        10\n",
      "        2601       0.55      0.38      0.44        64\n",
      "        2602       0.78      0.78      0.78        27\n",
      "        2603       0.00      0.00      0.00         1\n",
      "        2604       0.00      0.00      0.00         2\n",
      "        2605       1.00      0.17      0.30        23\n",
      "        2607       0.84      0.81      0.82       109\n",
      "        2608       0.60      0.25      0.35        12\n",
      "        2610       0.83      0.93      0.88       160\n",
      "        2631       0.94      0.84      0.89       108\n",
      "        2632       0.96      0.94      0.95        50\n",
      "        2633       0.00      0.00      0.00         6\n",
      "        2634       0.62      0.98      0.76       163\n",
      "        2635       1.00      0.57      0.73        28\n",
      "        2636       0.86      0.89      0.88        64\n",
      "        2662       0.93      0.78      0.85        36\n",
      "        2663       0.85      0.89      0.87       138\n",
      "        2672       1.00      0.64      0.78        11\n",
      "        2674       0.68      0.64      0.66        42\n",
      "        2675       0.00      0.00      0.00         5\n",
      "        2676       0.00      0.00      0.00         1\n",
      "        2677       0.83      0.36      0.50        28\n",
      "        2680       1.00      0.33      0.50         3\n",
      "        2681       0.00      0.00      0.00         6\n",
      "        2682       1.00      0.33      0.50         9\n",
      "        2683       0.00      0.00      0.00         4\n",
      "        2684       0.00      0.00      0.00         1\n",
      "        2688       0.00      0.00      0.00         1\n",
      "        2689       0.00      0.00      0.00        12\n",
      "        2690       0.71      0.80      0.75        30\n",
      "        2691       1.00      0.77      0.87        30\n",
      "        2692       0.93      0.85      0.89        61\n",
      "        2693       0.77      0.86      0.81       236\n",
      "        2725       0.89      0.68      0.77        25\n",
      "        2726       1.00      1.00      1.00         5\n",
      "        2727       1.00      0.18      0.30        17\n",
      "        2728       0.68      0.63      0.65        43\n",
      "        2729       0.80      0.73      0.76        33\n",
      "        2730       0.76      0.81      0.79        32\n",
      "        2731       0.54      0.88      0.67        17\n",
      "        2732       1.00      0.91      0.95        23\n",
      "        2733       1.00      0.75      0.86        24\n",
      "        2734       0.64      0.64      0.64        14\n",
      "        2735       1.00      0.95      0.98        21\n",
      "        2736       0.75      0.43      0.55         7\n",
      "        2737       0.71      0.50      0.59        34\n",
      "        2738       0.67      0.36      0.47        11\n",
      "        2739       0.85      0.92      0.88        48\n",
      "        2740       0.84      0.74      0.78        42\n",
      "        2741       0.62      0.71      0.66        65\n",
      "        2742       0.91      0.93      0.92        90\n",
      "        2743       0.95      0.95      0.95        43\n",
      "        2744       0.60      0.83      0.70       105\n",
      "        2745       1.00      0.75      0.86        12\n",
      "        2746       1.00      0.38      0.55         8\n",
      "        2747       0.49      0.42      0.45       169\n",
      "        2748       0.88      0.71      0.79        62\n",
      "        2750       0.68      0.46      0.55        93\n",
      "        2751       1.00      0.67      0.80         3\n",
      "        2800       0.00      0.00      0.00         2\n",
      "        2801       1.00      0.40      0.57         5\n",
      "        2802       1.00      0.60      0.75        10\n",
      "        2803       0.86      0.97      0.91       204\n",
      "        2804       0.59      0.72      0.65       119\n",
      "        2805       1.00      0.57      0.73         7\n",
      "        2823       0.00      0.00      0.00         1\n",
      "        2824       0.63      0.66      0.64        79\n",
      "        2825       0.57      0.83      0.67        36\n",
      "        2826       0.00      0.00      0.00         1\n",
      "        2827       0.68      0.42      0.52        36\n",
      "        2828       0.00      0.00      0.00         3\n",
      "        2829       0.00      0.00      0.00        10\n",
      "        2831       0.00      0.00      0.00         6\n",
      "        2833       0.65      0.61      0.63        28\n",
      "        2834       0.00      0.00      0.00         1\n",
      "        2837       0.84      0.64      0.73        25\n",
      "        2838       0.80      0.14      0.24        28\n",
      "        2839       0.00      0.00      0.00         3\n",
      "        2840       1.00      0.29      0.44         7\n",
      "        2841       0.20      0.07      0.11        14\n",
      "        2842       0.00      0.00      0.00         9\n",
      "        2844       0.00      0.00      0.00         1\n",
      "        2846       0.00      0.00      0.00         1\n",
      "        2847       0.00      0.00      0.00         1\n",
      "        2848       0.00      0.00      0.00         2\n",
      "        2851       0.75      0.36      0.49        25\n",
      "        2852       0.00      0.00      0.00         3\n",
      "        2854       0.00      0.00      0.00         1\n",
      "        2857       1.00      0.06      0.12        16\n",
      "        2858       0.71      0.48      0.57        25\n",
      "        2861       0.00      0.00      0.00         5\n",
      "        2862       0.00      0.00      0.00         5\n",
      "        2864       0.93      0.81      0.87        16\n",
      "        2865       1.00      0.90      0.95        21\n",
      "        2867       0.76      0.81      0.78        31\n",
      "        2876       1.00      0.20      0.33         5\n",
      "        2877       1.00      0.20      0.33         5\n",
      "        2895       0.88      0.64      0.74        11\n",
      "        2896       0.38      0.50      0.43        10\n",
      "        2897       1.00      0.42      0.59        12\n",
      "        2898       0.00      0.00      0.00         8\n",
      "       11530       0.98      0.98      0.98       115\n",
      "       11533       0.89      0.76      0.82        21\n",
      "       11536       0.75      0.38      0.50         8\n",
      "       11539       0.00      0.00      0.00         4\n",
      "       11540       1.00      0.29      0.45        17\n",
      "       11542       1.00      0.50      0.67         2\n",
      "       11546       1.00      0.08      0.15        12\n",
      "       11548       0.00      0.00      0.00         3\n",
      "       11549       0.00      0.00      0.00         4\n",
      "       11550       0.00      0.00      0.00         7\n",
      "       11552       0.86      0.83      0.85        53\n",
      "       11554       0.95      0.91      0.93        46\n",
      "       11560       0.75      0.63      0.69        52\n",
      "       11564       0.00      0.00      0.00         1\n",
      "       11565       0.00      0.00      0.00         4\n",
      "       11567       0.81      0.79      0.80       144\n",
      "       11568       0.97      0.88      0.93        43\n",
      "       11573       0.95      0.70      0.81        30\n",
      "       11574       0.79      0.96      0.87       448\n",
      "       11580       0.67      0.76      0.71        46\n",
      "       11581       0.50      0.25      0.33        44\n",
      "       11587       0.87      0.96      0.91        27\n",
      "       11593       0.00      0.00      0.00         8\n",
      "       11596       0.00      0.00      0.00        12\n",
      "       11597       0.75      0.70      0.72       123\n",
      "       11598       0.00      0.00      0.00         1\n",
      "       11600       0.86      0.76      0.81        55\n",
      "       11602       0.72      0.72      0.72        71\n",
      "       11603       0.74      0.74      0.74        35\n",
      "       11605       0.00      0.00      0.00         1\n",
      "       11613       1.00      0.64      0.78        50\n",
      "       11615       0.00      0.00      0.00         1\n",
      "       11617       0.40      0.69      0.51       361\n",
      "       11619       0.60      0.43      0.50         7\n",
      "       11622       0.61      0.83      0.70        24\n",
      "       11623       0.00      0.00      0.00         1\n",
      "       11626       0.00      0.00      0.00         2\n",
      "       11635       0.71      0.68      0.69        71\n",
      "       11636       0.75      0.75      0.75        16\n",
      "       11637       0.75      0.69      0.72        52\n",
      "       11638       0.00      0.00      0.00         2\n",
      "       11639       0.84      0.69      0.76        93\n",
      "       11643       0.00      0.00      0.00         1\n",
      "       11645       1.00      0.33      0.50         3\n",
      "       11647       0.89      0.69      0.78        48\n",
      "       11648       0.62      0.43      0.51        30\n",
      "       11649       1.00      0.77      0.87        13\n",
      "       11655       0.43      0.46      0.45        69\n",
      "       11657       0.84      1.00      0.91        21\n",
      "       11658       0.57      0.70      0.63        23\n",
      "       11659       1.00      0.76      0.87        17\n",
      "       11663       0.67      0.57      0.62         7\n",
      "       11670       1.00      0.67      0.80        24\n",
      "       11672       0.67      0.40      0.50         5\n",
      "       11674       1.00      0.75      0.86        24\n",
      "       11678       1.00      0.77      0.87        13\n",
      "       11681       0.85      0.82      0.84        34\n",
      "       11686       0.76      0.81      0.79        16\n",
      "       11694       0.74      0.58      0.65        24\n",
      "       11711       0.00      0.00      0.00         5\n",
      "       11713       0.00      0.00      0.00         1\n",
      "       11714       1.00      0.62      0.77         8\n",
      "       11716       1.00      0.21      0.34        48\n",
      "       11717       1.00      0.89      0.94        18\n",
      "       11719       0.72      1.00      0.84        26\n",
      "       11720       0.00      0.00      0.00         1\n",
      "       11722       0.00      0.00      0.00         1\n",
      "       11725       0.87      0.94      0.90       124\n",
      "       11730       0.00      0.00      0.00         9\n",
      "       11731       0.84      0.82      0.83        62\n",
      "       11732       0.00      0.00      0.00         3\n",
      "       11733       0.73      0.73      0.73        11\n",
      "       11734       0.00      0.00      0.00         7\n",
      "       11735       1.00      0.79      0.88        33\n",
      "       11736       0.89      0.29      0.43        28\n",
      "       11738       1.00      0.33      0.50         3\n",
      "       11745       0.76      0.46      0.57        48\n",
      "       11750       0.62      0.93      0.74        54\n",
      "       11751       0.83      0.77      0.80        13\n",
      "       11753       0.00      0.00      0.00         2\n",
      "       11756       0.82      0.78      0.80        90\n",
      "       11757       0.83      0.94      0.88       383\n",
      "       11761       0.68      0.82      0.75        34\n",
      "       11762       0.64      0.72      0.68        50\n",
      "       11764       0.89      0.84      0.86        19\n",
      "       11767       0.00      0.00      0.00         3\n",
      "       11770       0.83      0.95      0.88       498\n",
      "       11771       0.00      0.00      0.00         4\n",
      "       11774       0.71      0.82      0.76        76\n",
      "       11778       0.94      0.71      0.81        21\n",
      "       11790       0.89      0.81      0.85       147\n",
      "       11793       0.67      0.67      0.67         3\n",
      "       11797       1.00      0.40      0.57         5\n",
      "       11799       0.91      0.99      0.95       182\n",
      "       11805       0.50      0.81      0.62        36\n",
      "       11813       0.75      0.85      0.80       379\n",
      "       11815       0.00      0.00      0.00         4\n",
      "       11820       1.00      0.80      0.89        10\n",
      "       11823       1.00      0.22      0.36         9\n",
      "       11824       0.00      0.00      0.00         4\n",
      "       11825       0.69      0.82      0.75        49\n",
      "       11826       0.87      0.84      0.85        31\n",
      "       11827       0.00      0.00      0.00         7\n",
      "       11828       0.56      0.58      0.57        38\n",
      "       11830       0.00      0.00      0.00         1\n",
      "       11836       0.91      0.77      0.83        13\n",
      "       11838       0.75      0.67      0.71        27\n",
      "       11841       1.00      0.67      0.80         9\n",
      "       11843       0.00      0.00      0.00         3\n",
      "       11844       0.88      0.29      0.43        49\n",
      "       11846       0.71      0.29      0.42        34\n",
      "       11848       1.00      0.50      0.67         6\n",
      "       11850       0.00      0.00      0.00         2\n",
      "       11854       0.00      0.00      0.00         9\n",
      "       11856       0.80      0.70      0.74        23\n",
      "       11863       0.71      0.52      0.60        23\n",
      "       11864       0.83      0.77      0.80        26\n",
      "       11871       0.00      0.00      0.00         2\n",
      "       11872       0.96      0.94      0.95       142\n",
      "       11873       0.00      0.00      0.00         2\n",
      "       11875       0.00      0.00      0.00         2\n",
      "       11878       0.84      0.94      0.89       304\n",
      "       11879       0.67      0.67      0.67         3\n",
      "       11881       0.95      0.78      0.86        23\n",
      "       11882       0.00      0.00      0.00        12\n",
      "       11889       0.81      0.61      0.70        36\n",
      "       11891       0.00      0.00      0.00         1\n",
      "       11894       0.81      0.98      0.89       330\n",
      "       11896       0.61      0.60      0.60        47\n",
      "       11897       1.00      0.12      0.22         8\n",
      "       11899       1.00      0.53      0.69        17\n",
      "       11902       0.82      1.00      0.90         9\n",
      "       11906       0.00      0.00      0.00         5\n",
      "       11907       0.60      0.42      0.49        50\n",
      "       11909       1.00      0.56      0.71         9\n",
      "       11913       0.00      0.00      0.00         1\n",
      "       11917       0.00      0.00      0.00         1\n",
      "       11922       0.00      0.00      0.00         1\n",
      "       11930       1.00      0.94      0.97        17\n",
      "       11931       0.89      0.89      0.89        71\n",
      "       11932       0.71      0.36      0.48        14\n",
      "       11935       1.00      0.43      0.60         7\n",
      "       11937       0.95      0.99      0.97      3002\n",
      "       11939       0.92      0.61      0.73        18\n",
      "       11942       1.00      0.50      0.67         2\n",
      "       11944       0.60      0.31      0.41        29\n",
      "       11946       0.33      0.08      0.12        13\n",
      "       11947       0.00      0.00      0.00         1\n",
      "       11949       1.00      0.81      0.90        16\n",
      "       11952       0.00      0.00      0.00         3\n",
      "       11956       0.76      0.87      0.81       422\n",
      "       11957       0.86      0.96      0.91       177\n",
      "       11959       0.00      0.00      0.00         3\n",
      "       11960       1.00      0.71      0.83         7\n",
      "       11961       0.83      0.83      0.83         6\n",
      "       11962       0.86      0.50      0.63        12\n",
      "       11967       0.88      0.78      0.82         9\n",
      "       11971       0.75      0.55      0.64        38\n",
      "       11972       0.00      0.00      0.00        10\n",
      "       11974       0.00      0.00      0.00         5\n",
      "       11977       0.00      0.00      0.00         2\n",
      "       11978       0.78      0.56      0.65        25\n",
      "       11980       0.90      0.75      0.82        24\n",
      "       11984       0.78      0.94      0.85        78\n",
      "       11985       0.00      0.00      0.00         2\n",
      "       11986       0.00      0.00      0.00         4\n",
      "       11993       0.00      0.00      0.00         1\n",
      "       11998       0.00      0.00      0.00         4\n",
      "       11999       0.75      0.70      0.72        54\n",
      "       12001       1.00      0.60      0.75         5\n",
      "       12004       0.94      0.85      0.89        20\n",
      "       12010       1.00      0.50      0.67         2\n",
      "       12011       1.00      0.33      0.50         3\n",
      "       12017       0.00      0.00      0.00         3\n",
      "       12023       0.77      0.67      0.71        15\n",
      "       12024       0.66      0.81      0.72        57\n",
      "       12032       0.90      1.00      0.95        35\n",
      "       12036       0.00      0.00      0.00         1\n",
      "       12039       0.45      0.62      0.53         8\n",
      "       12040       0.80      0.44      0.57         9\n",
      "       12044       0.85      0.98      0.91        95\n",
      "       12045       0.79      0.56      0.65        27\n",
      "       12046       0.00      0.00      0.00         1\n",
      "       12049       0.82      0.88      0.85       171\n",
      "       12050       0.96      0.79      0.86        56\n",
      "       12052       1.00      0.09      0.17        11\n",
      "       12055       0.00      0.00      0.00         2\n",
      "       12059       0.00      0.00      0.00         1\n",
      "       12060       0.00      0.00      0.00         2\n",
      "       12062       0.71      0.43      0.54        35\n",
      "       12067       0.00      0.00      0.00         2\n",
      "       12071       0.82      0.67      0.74        42\n",
      "       12074       0.00      0.00      0.00         2\n",
      "       12076       0.54      0.60      0.57        25\n",
      "       12077       0.89      0.62      0.73        13\n",
      "       12078       0.68      0.73      0.70       365\n",
      "       12081       1.00      0.12      0.22         8\n",
      "       12082       0.46      0.41      0.44       114\n",
      "       12084       1.00      0.50      0.67        28\n",
      "       12085       1.00      1.00      1.00         8\n",
      "       12088       0.84      0.81      0.83        32\n",
      "       12090       1.00      0.69      0.82        13\n",
      "       12092       0.00      0.00      0.00        10\n",
      "       12094       0.00      0.00      0.00         5\n",
      "       12097       1.00      0.86      0.92        14\n",
      "       12100       0.96      0.99      0.97       301\n",
      "       12102       0.00      0.00      0.00         3\n",
      "       12109       0.77      0.41      0.54        58\n",
      "       12111       0.71      0.62      0.67         8\n",
      "       12114       0.88      0.23      0.36        31\n",
      "       12118       0.00      0.00      0.00         1\n",
      "       12120       0.00      0.00      0.00         3\n",
      "       12128       0.59      0.89      0.71        37\n",
      "       12139       1.00      0.23      0.38        13\n",
      "       12142       0.64      0.54      0.58        13\n",
      "       12143       0.56      0.48      0.52        31\n",
      "       12144       0.90      0.94      0.92       116\n",
      "       12146       1.00      1.00      1.00         2\n",
      "       12147       0.75      0.53      0.62        17\n",
      "       12150       0.83      0.56      0.67         9\n",
      "       12154       0.76      0.63      0.69        82\n",
      "       12156       0.00      0.00      0.00         6\n",
      "       12157       0.88      0.81      0.84        26\n",
      "       12158       1.00      0.08      0.14        13\n",
      "       12159       0.95      0.98      0.97       366\n",
      "       12161       0.83      0.44      0.58        34\n",
      "       12162       0.63      0.22      0.33        77\n",
      "       12164       0.79      0.92      0.85        36\n",
      "       12167       0.56      0.75      0.64        12\n",
      "       12171       0.87      0.97      0.92       480\n",
      "       12172       0.00      0.00      0.00         7\n",
      "       12175       0.93      0.61      0.74        23\n",
      "       12176       0.96      0.92      0.94       157\n",
      "       12181       0.50      0.17      0.25         6\n",
      "       12185       0.86      0.82      0.84        22\n",
      "       12188       0.00      0.00      0.00         2\n",
      "       12192       0.42      0.29      0.34        17\n",
      "       12197       0.92      0.92      0.92       102\n",
      "       12198       0.86      1.00      0.92         6\n",
      "       12199       0.75      0.30      0.43        10\n",
      "       12208       0.00      0.00      0.00         2\n",
      "       12209       1.00      0.13      0.24        15\n",
      "       12210       0.87      0.93      0.90       410\n",
      "       12217       0.50      0.20      0.29        10\n",
      "       12219       0.00      0.00      0.00         2\n",
      "       12222       0.94      0.98      0.96       171\n",
      "       12223       0.00      0.00      0.00         3\n",
      "       12226       0.00      0.00      0.00         7\n",
      "       12228       0.93      0.95      0.94       214\n",
      "       12230       0.81      0.78      0.79       119\n",
      "       12237       0.80      0.57      0.67        14\n",
      "       12238       1.00      0.30      0.47        23\n",
      "       12240       0.00      0.00      0.00        15\n",
      "       12243       0.00      0.00      0.00         9\n",
      "       12246       0.76      0.83      0.80        47\n",
      "       12247       0.89      0.62      0.73        39\n",
      "       12249       1.00      0.88      0.94        17\n",
      "       12250       0.68      0.81      0.74        67\n",
      "       12251       0.83      0.86      0.84       148\n",
      "       12254       0.85      0.92      0.88        25\n",
      "       12255       0.00      0.00      0.00         9\n",
      "       12256       0.00      0.00      0.00         5\n",
      "       12257       0.00      0.00      0.00         9\n",
      "       12262       0.00      0.00      0.00         8\n",
      "       12265       0.91      0.99      0.95       203\n",
      "       12267       0.90      0.89      0.89        62\n",
      "       12268       0.79      0.70      0.75        27\n",
      "       12272       0.96      0.96      0.96       208\n",
      "       12273       0.87      0.54      0.67        24\n",
      "       12274       0.00      0.00      0.00         4\n",
      "       12275       0.80      1.00      0.89         4\n",
      "       12276       0.00      0.00      0.00         2\n",
      "       12279       0.56      0.64      0.60        14\n",
      "       12280       0.60      0.38      0.46        16\n",
      "       12282       0.67      0.74      0.70       296\n",
      "       12283       0.00      0.00      0.00         3\n",
      "       12285       1.00      1.00      1.00         6\n",
      "       12286       0.00      0.00      0.00         2\n",
      "       12287       1.00      0.37      0.54        19\n",
      "       12297       0.60      0.60      0.60        60\n",
      "       12301       0.94      0.95      0.95       415\n",
      "       12302       0.76      0.63      0.69       142\n",
      "       12304       0.00      0.00      0.00        11\n",
      "       12308       0.89      0.65      0.76        26\n",
      "       12309       1.00      0.72      0.84        18\n",
      "       12310       0.00      0.00      0.00         7\n",
      "       12313       0.00      0.00      0.00         1\n",
      "       12314       0.00      0.00      0.00         3\n",
      "       12315       0.87      0.92      0.90        51\n",
      "       12317       1.00      0.70      0.82        10\n",
      "       12318       0.83      0.67      0.74        15\n",
      "       12319       0.00      0.00      0.00         2\n",
      "       12320       0.00      0.00      0.00         5\n",
      "       12321       0.00      0.00      0.00         4\n",
      "       12324       1.00      1.00      1.00         3\n",
      "       12326       0.00      0.00      0.00         3\n",
      "       12327       0.00      0.00      0.00         3\n",
      "       12328       0.84      0.72      0.78        36\n",
      "       12329       0.00      0.00      0.00         2\n",
      "       12330       0.80      0.92      0.86       146\n",
      "       12337       0.73      0.73      0.73        11\n",
      "       12338       0.61      0.59      0.60        34\n",
      "       12339       0.00      0.00      0.00         2\n",
      "       12340       0.00      0.00      0.00         3\n",
      "       12341       0.64      0.68      0.66        53\n",
      "       12349       0.78      1.00      0.88         7\n",
      "       12350       0.68      0.95      0.80       252\n",
      "       12352       0.62      0.92      0.74        50\n",
      "       12354       0.55      0.24      0.34        49\n",
      "       12358       0.00      0.00      0.00         1\n",
      "       12362       0.00      0.00      0.00         1\n",
      "       12364       0.00      0.00      0.00         6\n",
      "       12365       0.00      0.00      0.00         1\n",
      "       12367       0.00      0.00      0.00         4\n",
      "       12372       1.00      0.06      0.11        17\n",
      "       12373       0.00      0.00      0.00         3\n",
      "       12376       1.00      0.16      0.28        31\n",
      "       12378       1.00      0.05      0.09        21\n",
      "       12379       1.00      0.73      0.84        11\n",
      "       12381       0.75      0.73      0.74       200\n",
      "       12384       0.00      0.00      0.00         4\n",
      "       12391       1.00      0.50      0.67         4\n",
      "       12394       0.86      0.97      0.91       167\n",
      "       12395       0.84      0.72      0.77        43\n",
      "       12396       0.00      0.00      0.00         1\n",
      "       12398       0.00      0.00      0.00         7\n",
      "       12401       0.64      0.76      0.69       227\n",
      "       12405       0.84      0.93      0.88       165\n",
      "       12407       0.78      0.76      0.77        38\n",
      "       12409       0.72      0.88      0.79        59\n",
      "       12415       0.71      0.97      0.82       226\n",
      "       12418       0.00      0.00      0.00         2\n",
      "       12422       0.91      0.89      0.90       142\n",
      "       12427       0.83      0.71      0.76        41\n",
      "       12428       0.78      0.45      0.57        31\n",
      "       12430       0.00      0.00      0.00         2\n",
      "       12433       0.50      0.29      0.36         7\n",
      "       12434       0.75      0.17      0.28        53\n",
      "       12436       1.00      0.50      0.67         6\n",
      "       12437       0.00      0.00      0.00         1\n",
      "       12438       0.00      0.00      0.00         9\n",
      "       12439       0.87      0.95      0.91        73\n",
      "       12442       0.80      0.27      0.40        15\n",
      "       12444       1.00      0.06      0.11        17\n",
      "       12451       0.73      0.52      0.61        61\n",
      "       12454       0.90      0.97      0.93       449\n",
      "       12456       0.85      0.93      0.89        95\n",
      "       12457       0.00      0.00      0.00         1\n",
      "       12460       0.93      0.60      0.72        42\n",
      "       12461       1.00      0.11      0.20         9\n",
      "       12464       0.86      0.55      0.67        11\n",
      "       12466       0.95      0.69      0.80        26\n",
      "       12468       0.00      0.00      0.00         1\n",
      "       12476       0.71      0.85      0.77       316\n",
      "       12477       0.99      0.97      0.98        75\n",
      "       12478       0.83      0.51      0.63        69\n",
      "       12479       1.00      0.69      0.82        55\n",
      "       12481       0.97      0.97      0.97        38\n",
      "       12482       0.73      0.88      0.80        84\n",
      "       12483       0.92      0.96      0.94        24\n",
      "       12486       1.00      0.33      0.50         9\n",
      "       12488       1.00      0.37      0.54        19\n",
      "       12493       0.86      0.59      0.70       126\n",
      "       12494       0.00      0.00      0.00        15\n",
      "       12502       1.00      0.10      0.18        10\n",
      "       12506       0.00      0.00      0.00         2\n",
      "       12509       0.86      0.95      0.90        82\n",
      "       12510       0.97      0.93      0.95        41\n",
      "       12512       0.66      0.79      0.72        75\n",
      "       12514       0.92      0.85      0.88       102\n",
      "       12515       0.67      0.38      0.48        16\n",
      "       12517       0.96      0.94      0.95        80\n",
      "       12520       0.00      0.00      0.00         2\n",
      "       12521       0.86      0.78      0.82        40\n",
      "       12523       0.97      0.84      0.90        45\n",
      "       12524       0.65      0.73      0.68       113\n",
      "       12525       0.00      0.00      0.00         2\n",
      "       12526       1.00      0.81      0.89        26\n",
      "       12529       1.00      0.62      0.77        16\n",
      "       12530       0.00      0.00      0.00         2\n",
      "       12534       1.00      0.57      0.72        23\n",
      "       12539       0.86      0.58      0.69        33\n",
      "       12541       0.95      0.95      0.95        66\n",
      "       12542       0.00      0.00      0.00         1\n",
      "       12544       0.00      0.00      0.00         1\n",
      "       12545       0.90      0.94      0.92        97\n",
      "       12548       0.85      0.83      0.84       203\n",
      "       12549       1.00      0.76      0.86        21\n",
      "       12553       0.80      0.75      0.77        16\n",
      "       12554       1.00      0.44      0.61        16\n",
      "       12556       0.76      0.64      0.69        58\n",
      "       12558       1.00      0.41      0.58        22\n",
      "       12567       0.95      0.82      0.88        22\n",
      "       12569       0.93      0.74      0.82        19\n",
      "       12577       0.00      0.00      0.00         1\n",
      "       12578       0.00      0.00      0.00         2\n",
      "       12579       0.72      0.80      0.76       263\n",
      "       12580       0.00      0.00      0.00         4\n",
      "       12584       0.00      0.00      0.00         2\n",
      "       12588       1.00      0.87      0.93        15\n",
      "       12589       0.85      0.92      0.88        72\n",
      "       12595       0.84      0.93      0.88        99\n",
      "       12596       0.00      0.00      0.00         4\n",
      "       12601       0.00      0.00      0.00         9\n",
      "       12602       0.50      0.09      0.15        11\n",
      "       12603       1.00      0.85      0.92        20\n",
      "       12604       0.93      0.97      0.95       677\n",
      "       12609       0.00      0.00      0.00         3\n",
      "       12611       1.00      0.20      0.33         5\n",
      "       12612       0.55      0.50      0.52        12\n",
      "       12614       1.00      0.80      0.89        10\n",
      "       12615       0.00      0.00      0.00        12\n",
      "       12616       0.94      0.76      0.84        42\n",
      "       12618       0.90      0.81      0.86       102\n",
      "       12622       0.00      0.00      0.00         4\n",
      "       12624       0.67      0.44      0.53        27\n",
      "       12625       0.00      0.00      0.00         2\n",
      "       12630       0.86      0.95      0.90       444\n",
      "       12631       0.00      0.00      0.00         1\n",
      "       12635       0.00      0.00      0.00         2\n",
      "       12638       1.00      1.00      1.00        15\n",
      "       12641       0.67      0.62      0.65        16\n",
      "       12642       0.81      0.94      0.87        51\n",
      "       12645       0.00      0.00      0.00         1\n",
      "       12646       0.67      0.50      0.57         4\n",
      "       12647       0.29      0.22      0.25         9\n",
      "       12648       0.97      0.88      0.92        34\n",
      "       12649       1.00      0.64      0.78        22\n",
      "       12652       0.79      0.74      0.76        35\n",
      "       12657       0.93      0.93      0.93       181\n",
      "       12658       0.73      0.79      0.76        24\n",
      "       12660       0.84      0.71      0.77        59\n",
      "       12661       0.00      0.00      0.00         3\n",
      "       12664       0.00      0.00      0.00         3\n",
      "       12665       0.00      0.00      0.00         2\n",
      "       12666       0.96      0.68      0.79        37\n",
      "       12667       0.67      0.77      0.72        74\n",
      "       12669       0.96      0.96      0.96        47\n",
      "       12674       0.83      0.80      0.82        50\n",
      "       12677       0.00      0.00      0.00         2\n",
      "       12681       0.30      1.00      0.46         3\n",
      "       12686       0.00      0.00      0.00         5\n",
      "       12690       1.00      0.87      0.93        31\n",
      "       12693       0.00      0.00      0.00         1\n",
      "       12694       0.76      0.85      0.80        41\n",
      "       12696       0.00      0.00      0.00         3\n",
      "       12697       0.78      0.78      0.78         9\n",
      "       12699       1.00      0.39      0.56        23\n",
      "       12700       0.00      0.00      0.00         1\n",
      "       12710       0.00      0.00      0.00         3\n",
      "       12711       0.80      0.27      0.40        15\n",
      "       12712       0.00      0.00      0.00         6\n",
      "       12713       0.93      0.88      0.91        49\n",
      "       12718       0.83      0.72      0.77        87\n",
      "       12720       0.50      0.71      0.59         7\n",
      "       12721       1.00      0.09      0.17        11\n",
      "       12725       0.00      0.00      0.00        12\n",
      "       12726       1.00      1.00      1.00         4\n",
      "       12727       1.00      0.50      0.67         2\n",
      "       12730       0.58      0.63      0.61       240\n",
      "       12731       0.59      0.78      0.68       137\n",
      "       12733       0.00      0.00      0.00         1\n",
      "       12736       0.98      0.93      0.95        45\n",
      "       12740       0.50      0.36      0.42        14\n",
      "       12741       0.71      0.86      0.78       181\n",
      "       12743       0.83      0.74      0.78       117\n",
      "       12745       0.67      0.22      0.33         9\n",
      "       12747       0.89      0.50      0.64        16\n",
      "       12750       1.00      0.50      0.67         2\n",
      "       12751       0.72      0.73      0.73       530\n",
      "       12753       0.86      0.75      0.80         8\n",
      "       12755       0.94      0.98      0.96       132\n",
      "       12761       0.83      0.95      0.89       188\n",
      "       12768       0.72      0.95      0.82        41\n",
      "       12769       0.67      0.40      0.50         5\n",
      "       12771       0.71      0.83      0.77         6\n",
      "       12773       0.88      0.44      0.58        16\n",
      "       12774       0.80      0.62      0.70        13\n",
      "       12775       0.00      0.00      0.00         5\n",
      "       12776       0.00      0.00      0.00         3\n",
      "       12781       0.90      0.99      0.95       210\n",
      "       12783       0.00      0.00      0.00         1\n",
      "       12788       0.57      0.74      0.64        23\n",
      "       12789       1.00      0.17      0.29         6\n",
      "       12797       0.00      0.00      0.00         1\n",
      "       12799       0.00      0.00      0.00         1\n",
      "       12802       0.00      0.00      0.00         2\n",
      "       12811       1.00      0.29      0.44         7\n",
      "       12813       0.95      0.94      0.94       203\n",
      "       12819       0.92      0.84      0.88        57\n",
      "       12822       0.00      0.00      0.00         2\n",
      "       12828       1.00      0.68      0.81        19\n",
      "       12829       0.90      0.79      0.84        24\n",
      "       12831       0.85      0.94      0.89        18\n",
      "       12834       0.87      0.89      0.88       361\n",
      "       12836       0.00      0.00      0.00         2\n",
      "       12841       0.84      0.80      0.82        92\n",
      "       12843       0.00      0.00      0.00         6\n",
      "       12844       0.00      0.00      0.00         4\n",
      "       12851       0.00      0.00      0.00         2\n",
      "       12863       0.55      0.64      0.59        42\n",
      "       12864       0.00      0.00      0.00         5\n",
      "       12865       0.50      0.07      0.12        15\n",
      "       12869       0.92      0.88      0.90        25\n",
      "       12870       0.94      0.64      0.76        25\n",
      "       12874       0.00      0.00      0.00         3\n",
      "       12882       0.70      0.93      0.80        55\n",
      "       12884       1.00      0.17      0.29         6\n",
      "       12887       0.67      0.80      0.73         5\n",
      "       12888       1.00      0.27      0.43        11\n",
      "       12889       1.00      0.14      0.25         7\n",
      "       12893       0.00      0.00      0.00         7\n",
      "       12895       0.95      0.71      0.82        56\n",
      "       12896       0.43      0.50      0.46         6\n",
      "       12901       0.00      0.00      0.00         2\n",
      "       12902       0.00      0.00      0.00         1\n",
      "       12907       1.00      0.40      0.57        20\n",
      "       12909       0.65      0.61      0.63       181\n",
      "       12910       0.61      0.71      0.66        28\n",
      "       12913       0.88      0.57      0.69        49\n",
      "       12914       0.82      0.96      0.89       231\n",
      "       12917       1.00      0.07      0.13        14\n",
      "       12919       0.94      0.92      0.93        36\n",
      "       12920       0.71      0.19      0.29        27\n",
      "       12926       1.00      0.67      0.80         6\n",
      "       12928       0.00      0.00      0.00         2\n",
      "       12930       1.00      0.62      0.77         8\n",
      "       12943       0.89      0.91      0.90        80\n",
      "       12945       0.00      0.00      0.00         4\n",
      "       12948       0.64      0.89      0.75        53\n",
      "       12950       0.00      0.00      0.00         1\n",
      "       12952       0.82      0.90      0.86        31\n",
      "       12953       0.00      0.00      0.00         2\n",
      "       12956       0.98      0.95      0.97        63\n",
      "       12958       0.00      0.00      0.00         6\n",
      "       12959       0.00      0.00      0.00         5\n",
      "       12961       0.75      0.33      0.46        18\n",
      "       12964       0.97      0.60      0.74        47\n",
      "       12967       0.00      0.00      0.00         1\n",
      "       12968       0.91      0.71      0.80        14\n",
      "       12971       0.00      0.00      0.00         2\n",
      "       12974       0.00      0.00      0.00         7\n",
      "       12975       1.00      0.25      0.40         4\n",
      "       12977       0.00      0.00      0.00         2\n",
      "       12978       0.63      1.00      0.78        26\n",
      "       12980       0.95      0.97      0.96       297\n",
      "       12982       0.00      0.00      0.00         2\n",
      "       12984       0.75      0.57      0.65        47\n",
      "       12987       0.71      0.56      0.63         9\n",
      "       12991       0.93      0.89      0.91        87\n",
      "       12992       0.43      0.48      0.45        42\n",
      "       12998       0.00      0.00      0.00         7\n",
      "       13000       1.00      1.00      1.00         6\n",
      "       13001       1.00      0.20      0.33         5\n",
      "       13007       0.00      0.00      0.00         1\n",
      "       13014       0.00      0.00      0.00         1\n",
      "       13019       0.00      0.00      0.00         5\n",
      "       13020       0.00      0.00      0.00         4\n",
      "       13021       0.96      0.96      0.96       102\n",
      "       13024       0.75      0.92      0.83        63\n",
      "       13027       0.80      0.78      0.79        36\n",
      "       13030       0.00      0.00      0.00         1\n",
      "       13031       0.00      0.00      0.00         1\n",
      "       13035       0.00      0.00      0.00         4\n",
      "       13040       1.00      0.72      0.84        40\n",
      "       13042       0.00      0.00      0.00         1\n",
      "       13043       0.76      0.87      0.81        15\n",
      "       13049       0.77      0.90      0.83        30\n",
      "       13052       0.00      0.00      0.00         1\n",
      "       13061       0.67      0.99      0.80      1285\n",
      "       13063       0.52      0.57      0.55        21\n",
      "       13065       0.79      0.85      0.81        13\n",
      "       13066       0.93      0.97      0.95       570\n",
      "       13068       0.70      0.30      0.42        23\n",
      "       13069       0.49      0.67      0.57       116\n",
      "       13072       1.00      0.71      0.83         7\n",
      "       13076       0.67      0.46      0.55        13\n",
      "       13083       0.91      0.94      0.92        98\n",
      "       13085       1.00      0.50      0.67         2\n",
      "       13087       0.00      0.00      0.00         2\n",
      "       13088       1.00      0.80      0.89         5\n",
      "       13090       0.00      0.00      0.00         6\n",
      "       13091       0.72      0.85      0.78       117\n",
      "       13094       0.89      0.91      0.90       155\n",
      "       13095       0.90      0.76      0.82        46\n",
      "       13096       0.00      0.00      0.00         3\n",
      "       13098       0.00      0.00      0.00         2\n",
      "       13100       0.76      0.76      0.76        17\n",
      "       13104       0.75      0.64      0.69        14\n",
      "       13114       0.93      0.91      0.92        44\n",
      "       13116       0.00      0.00      0.00         1\n",
      "       13123       0.00      0.00      0.00         5\n",
      "       13127       0.00      0.00      0.00         1\n",
      "       13135       0.57      0.33      0.42        12\n",
      "       13138       1.00      0.33      0.50         6\n",
      "       13139       0.44      0.17      0.25        47\n",
      "       13143       0.81      0.96      0.88      1200\n",
      "       13145       0.86      0.75      0.80         8\n",
      "       13146       1.00      0.77      0.87        13\n",
      "       13150       0.00      0.00      0.00         4\n",
      "       13151       0.50      0.20      0.29        10\n",
      "       13153       0.86      0.67      0.75         9\n",
      "       13155       0.71      0.88      0.79        52\n",
      "       13157       0.44      0.70      0.54        10\n",
      "       13159       0.71      0.50      0.59        10\n",
      "       13162       0.90      0.87      0.88       128\n",
      "       13165       0.78      0.61      0.68        41\n",
      "       13166       0.56      0.72      0.63        25\n",
      "       13169       0.00      0.00      0.00         1\n",
      "       13170       1.00      0.19      0.32        16\n",
      "       13171       0.78      0.61      0.68        51\n",
      "       13172       1.00      0.67      0.80        18\n",
      "       13179       0.83      0.88      0.86        17\n",
      "       13182       1.00      0.96      0.98        46\n",
      "       13184       0.00      0.00      0.00         3\n",
      "       13185       0.00      0.00      0.00         9\n",
      "       13187       0.92      0.95      0.94        63\n",
      "       13188       1.00      0.11      0.20         9\n",
      "       13192       0.91      0.86      0.88        58\n",
      "       13196       0.00      0.00      0.00         1\n",
      "       13199       0.78      0.81      0.79        67\n",
      "       13201       0.80      0.77      0.79        31\n",
      "       13203       0.70      0.90      0.79       364\n",
      "       13205       0.52      0.67      0.58       132\n",
      "       13207       0.85      0.83      0.84        48\n",
      "       13209       0.00      0.00      0.00         1\n",
      "       13210       0.00      0.00      0.00         5\n",
      "       13212       0.00      0.00      0.00         1\n",
      "       13215       1.00      1.00      1.00        17\n",
      "       13217       0.00      0.00      0.00         2\n",
      "       13220       0.69      0.84      0.76        77\n",
      "       13227       0.55      0.42      0.47        43\n",
      "       13228       0.82      0.88      0.85        16\n",
      "       13230       1.00      0.86      0.92        14\n",
      "       13234       1.00      0.11      0.20         9\n",
      "       13235       0.00      0.00      0.00         3\n",
      "       13237       0.00      0.00      0.00         2\n",
      "       13240       0.00      0.00      0.00         6\n",
      "       13253       0.89      0.75      0.81       681\n",
      "       13254       0.61      0.59      0.60       143\n",
      "       13258       0.00      0.00      0.00        15\n",
      "       13260       0.94      0.86      0.90        36\n",
      "       13268       0.60      0.63      0.62        19\n",
      "       13269       0.94      0.98      0.96       133\n",
      "       13271       0.83      0.71      0.76        41\n",
      "       13273       0.00      0.00      0.00        14\n",
      "       13274       0.74      0.61      0.67        41\n",
      "       13277       0.82      0.70      0.75        96\n",
      "       13281       0.00      0.00      0.00         1\n",
      "       13286       1.00      0.64      0.78        11\n",
      "       13289       0.00      0.00      0.00         2\n",
      "       13296       0.00      0.00      0.00         2\n",
      "       13297       0.55      0.39      0.45        44\n",
      "       13299       0.76      0.88      0.81        25\n",
      "       13302       0.70      0.70      0.70        20\n",
      "       13304       0.90      0.82      0.86        11\n",
      "       13306       0.73      0.58      0.65        19\n",
      "       13310       0.86      0.50      0.63        12\n",
      "       13312       0.60      0.13      0.21        46\n",
      "       13313       0.90      0.75      0.82        12\n",
      "       13322       0.96      0.94      0.95        51\n",
      "       13324       0.49      0.58      0.53        86\n",
      "       13325       0.88      0.88      0.88         8\n",
      "       13327       0.96      1.00      0.98        25\n",
      "       13328       0.82      0.43      0.56        21\n",
      "       13333       0.00      0.00      0.00         3\n",
      "       13334       0.00      0.00      0.00         1\n",
      "       13335       1.00      0.75      0.86        20\n",
      "       13337       0.50      0.60      0.55         5\n",
      "       13338       0.00      0.00      0.00         3\n",
      "       13340       0.00      0.00      0.00         3\n",
      "       13342       0.83      0.42      0.56        12\n",
      "       13343       0.74      0.64      0.68        22\n",
      "       13344       0.80      1.00      0.89       148\n",
      "       13346       0.00      0.00      0.00         7\n",
      "       13348       0.75      0.50      0.60         6\n",
      "       13350       1.00      0.22      0.36         9\n",
      "       13352       0.51      0.70      0.59        69\n",
      "       13358       0.88      0.98      0.93       127\n",
      "       13362       0.80      0.81      0.81        54\n",
      "       13365       0.79      0.58      0.67        38\n",
      "       13371       0.92      0.92      0.92        12\n",
      "       13376       0.83      0.83      0.83         6\n",
      "       13377       0.29      0.29      0.29         7\n",
      "       13379       0.00      0.00      0.00         8\n",
      "       13381       0.93      0.94      0.93        66\n",
      "       13384       0.78      0.86      0.82        72\n",
      "       13388       0.85      0.85      0.85        13\n",
      "       13390       0.50      0.12      0.20         8\n",
      "       13393       0.72      0.79      0.75       163\n",
      "       13395       0.00      0.00      0.00         2\n",
      "       13403       0.70      0.66      0.68       157\n",
      "       13406       0.00      0.00      0.00         3\n",
      "       13407       0.82      0.94      0.88       649\n",
      "       13408       0.96      0.99      0.97      1438\n",
      "       13409       0.76      0.70      0.73        27\n",
      "       13414       0.86      0.66      0.75        29\n",
      "       13415       0.00      0.00      0.00         6\n",
      "       13419       0.79      0.92      0.85        25\n",
      "       13420       0.00      0.00      0.00         2\n",
      "       13421       0.00      0.00      0.00         1\n",
      "       13423       0.00      0.00      0.00         5\n",
      "       13424       0.94      0.64      0.76        47\n",
      "       13425       0.00      0.00      0.00         5\n",
      "       13427       0.76      0.92      0.83        37\n",
      "       13433       0.80      0.44      0.57         9\n",
      "       13434       0.48      0.78      0.60        18\n",
      "       13439       0.00      0.00      0.00         4\n",
      "       13442       0.81      0.64      0.71        47\n",
      "       13445       0.00      0.00      0.00         1\n",
      "       13447       0.00      0.00      0.00         1\n",
      "       13451       0.70      0.71      0.71        90\n",
      "       13453       0.88      0.83      0.86        18\n",
      "       13462       0.33      0.09      0.14        11\n",
      "       13466       0.83      0.31      0.45        16\n",
      "       13469       0.82      0.75      0.78        12\n",
      "       13471       0.00      0.00      0.00         6\n",
      "       13474       0.69      0.61      0.65        66\n",
      "       13481       0.00      0.00      0.00         1\n",
      "       13484       1.00      0.20      0.33         5\n",
      "       13485       0.00      0.00      0.00         9\n",
      "       13486       0.83      0.95      0.88       112\n",
      "       13488       0.00      0.00      0.00         1\n",
      "       13490       0.00      0.00      0.00         2\n",
      "       13493       1.00      0.67      0.80         6\n",
      "       13495       0.95      0.97      0.96       357\n",
      "       13497       0.93      0.82      0.87        17\n",
      "       13500       0.50      0.50      0.50         4\n",
      "       13501       1.00      0.25      0.40         4\n",
      "       13504       0.00      0.00      0.00         5\n",
      "       13507       0.67      0.33      0.44        18\n",
      "       13509       0.92      0.89      0.90       170\n",
      "       13511       0.80      0.93      0.86        89\n",
      "       13513       0.00      0.00      0.00         2\n",
      "       13515       0.69      0.69      0.69        26\n",
      "       13520       0.00      0.00      0.00         3\n",
      "       13527       0.67      0.79      0.73       136\n",
      "       13528       0.85      0.90      0.87       196\n",
      "       13529       0.00      0.00      0.00        11\n",
      "       13530       0.97      0.90      0.94        72\n",
      "       13532       0.00      0.00      0.00         8\n",
      "       13533       0.96      0.93      0.95        59\n",
      "       13535       0.86      0.89      0.87        27\n",
      "       13537       0.68      0.48      0.56        86\n",
      "       13542       0.50      0.20      0.29         5\n",
      "       13545       1.00      0.47      0.64        19\n",
      "       13546       0.00      0.00      0.00         5\n",
      "       13547       0.00      0.00      0.00         4\n",
      "       13549       0.00      0.00      0.00         7\n",
      "       13551       0.00      0.00      0.00         6\n",
      "       13552       0.94      0.93      0.94       273\n",
      "       13554       0.72      0.92      0.81       220\n",
      "       13555       0.00      0.00      0.00         1\n",
      "       13559       0.00      0.00      0.00         5\n",
      "       13560       0.00      0.00      0.00         1\n",
      "       13562       0.00      0.00      0.00         4\n",
      "       13564       0.59      0.67      0.62        30\n",
      "       13565       0.00      0.00      0.00        18\n",
      "       13568       0.00      0.00      0.00         2\n",
      "       13570       0.00      0.00      0.00         5\n",
      "       13573       1.00      0.62      0.76        13\n",
      "       13579       0.00      0.00      0.00         8\n",
      "       13581       1.00      0.67      0.80         3\n",
      "       13588       0.75      0.35      0.47        26\n",
      "       13589       0.90      0.31      0.46        29\n",
      "       13593       0.00      0.00      0.00         7\n",
      "       13594       0.88      0.85      0.86        94\n",
      "       13603       1.00      0.20      0.33        10\n",
      "       13604       0.70      0.61      0.65        51\n",
      "       13605       0.00      0.00      0.00         4\n",
      "       13607       1.00      0.11      0.20         9\n",
      "       13608       0.67      0.44      0.53         9\n",
      "       13611       0.46      0.90      0.61        21\n",
      "       13613       0.83      0.79      0.81        24\n",
      "       13614       0.59      0.89      0.71       194\n",
      "       13615       0.85      0.63      0.72        27\n",
      "       13616       0.86      0.88      0.87       111\n",
      "       13619       1.00      0.45      0.62        22\n",
      "       13626       0.00      0.00      0.00         1\n",
      "       13632       0.00      0.00      0.00         3\n",
      "       13640       0.00      0.00      0.00         2\n",
      "       13648       0.89      0.85      0.87        48\n",
      "       13649       0.93      0.38      0.54        71\n",
      "       13652       0.00      0.00      0.00         4\n",
      "       13658       1.00      0.83      0.91         6\n",
      "       13661       0.67      0.20      0.31        10\n",
      "       13667       1.00      0.33      0.50         3\n",
      "       13673       0.00      0.00      0.00        19\n",
      "       13674       0.76      0.83      0.79       150\n",
      "       13675       0.00      0.00      0.00         1\n",
      "       13676       0.92      0.25      0.39        44\n",
      "       13679       0.80      0.33      0.47        12\n",
      "       13684       0.87      0.43      0.58        76\n",
      "       13685       0.67      0.77      0.71        13\n",
      "       13693       1.00      0.20      0.33         5\n",
      "       13694       0.88      0.92      0.90       167\n",
      "       13699       0.00      0.00      0.00         1\n",
      "       13700       0.81      0.50      0.62        44\n",
      "       13704       0.50      0.93      0.65        15\n",
      "       13706       0.00      0.00      0.00         8\n",
      "       13707       0.00      0.00      0.00         2\n",
      "       13708       0.89      0.97      0.93       248\n",
      "       13712       0.90      0.82      0.86        77\n",
      "       13714       0.84      0.81      0.83        85\n",
      "       13715       0.00      0.00      0.00         4\n",
      "       13726       0.62      0.70      0.66        33\n",
      "       13727       0.61      0.97      0.75        36\n",
      "       13728       1.00      0.67      0.80         3\n",
      "       13729       0.71      0.80      0.75        50\n",
      "       13733       0.00      0.00      0.00         1\n",
      "       13736       0.00      0.00      0.00         8\n",
      "       13738       0.00      0.00      0.00         1\n",
      "       13739       1.00      0.50      0.67         4\n",
      "       13745       0.61      0.92      0.73       160\n",
      "       13752       0.62      0.24      0.34        21\n",
      "       13754       0.00      0.00      0.00         3\n",
      "       13755       0.80      0.82      0.81       100\n",
      "       13765       0.00      0.00      0.00         6\n",
      "       13766       0.00      0.00      0.00         3\n",
      "       13770       0.37      0.31      0.34        88\n",
      "       13775       0.87      0.67      0.75        30\n",
      "       13776       0.00      0.00      0.00         8\n",
      "       13779       0.00      0.00      0.00         7\n",
      "       13781       0.85      0.65      0.73        17\n",
      "       13786       0.95      0.95      0.95        75\n",
      "       13788       0.00      0.00      0.00        10\n",
      "       13793       1.00      0.17      0.29        12\n",
      "       13795       0.86      0.88      0.87        69\n",
      "       13798       0.70      0.80      0.74        20\n",
      "       13799       0.81      0.89      0.85       136\n",
      "       13802       0.00      0.00      0.00         1\n",
      "       13803       0.72      0.52      0.60        56\n",
      "       13808       0.70      0.85      0.77        33\n",
      "       13812       0.00      0.00      0.00         3\n",
      "       13814       0.00      0.00      0.00         2\n",
      "       13816       0.93      0.95      0.94       256\n",
      "       13818       0.00      0.00      0.00         1\n",
      "       13822       0.86      0.24      0.38        25\n",
      "       13823       0.75      0.60      0.67        15\n",
      "       13824       0.97      0.99      0.98       107\n",
      "       13827       0.72      0.67      0.69       116\n",
      "       13828       0.00      0.00      0.00         1\n",
      "       13831       0.71      0.62      0.67         8\n",
      "       13833       0.83      0.56      0.67        27\n",
      "       13835       0.93      0.99      0.96       134\n",
      "       13836       0.00      0.00      0.00         3\n",
      "       13839       0.71      0.55      0.62        22\n",
      "       13841       1.00      0.27      0.43        11\n",
      "       13844       0.00      0.00      0.00         3\n",
      "       13847       0.88      0.88      0.88         8\n",
      "       13852       0.00      0.00      0.00         4\n",
      "       13855       0.90      0.90      0.90        21\n",
      "       13860       0.00      0.00      0.00         4\n",
      "       13861       1.00      0.50      0.67         8\n",
      "       13870       0.00      0.00      0.00         7\n",
      "       13873       1.00      0.09      0.17        11\n",
      "       13879       0.75      0.50      0.60         6\n",
      "       13880       0.95      0.92      0.94       105\n",
      "       13883       0.88      0.95      0.91        22\n",
      "       13885       1.00      0.77      0.87        13\n",
      "       13886       0.00      0.00      0.00         1\n",
      "       13887       0.56      0.54      0.55        28\n",
      "       13888       0.00      0.00      0.00         4\n",
      "       13891       1.00      0.50      0.67        14\n",
      "       13892       0.00      0.00      0.00         5\n",
      "       13893       1.00      0.22      0.36        18\n",
      "       13898       0.67      0.87      0.76       167\n",
      "       13901       0.75      0.81      0.78        93\n",
      "       13904       0.90      0.70      0.79        53\n",
      "       13905       0.93      0.72      0.81        36\n",
      "       13906       1.00      0.27      0.43        22\n",
      "       13912       0.00      0.00      0.00         1\n",
      "       13919       0.00      0.00      0.00         2\n",
      "       13921       0.00      0.00      0.00         2\n",
      "       13928       1.00      0.33      0.50         3\n",
      "       13932       0.00      0.00      0.00         3\n",
      "       13936       0.00      0.00      0.00         3\n",
      "       13938       0.85      1.00      0.92        45\n",
      "       13939       0.00      0.00      0.00         6\n",
      "       13941       0.98      0.89      0.93        47\n",
      "       13946       0.86      0.86      0.86         7\n",
      "       13948       0.50      0.33      0.40        15\n",
      "       13950       0.50      0.14      0.22         7\n",
      "       13951       1.00      0.89      0.94         9\n",
      "       13952       0.00      0.00      0.00         2\n",
      "       13954       0.72      0.67      0.70       211\n",
      "       13955       0.86      0.60      0.71        10\n",
      "       13956       0.93      0.94      0.93       158\n",
      "       13959       0.00      0.00      0.00         1\n",
      "       13961       0.00      0.00      0.00         8\n",
      "       13963       0.78      0.33      0.47        21\n",
      "       13968       1.00      0.25      0.40        16\n",
      "       13973       0.67      0.47      0.55        30\n",
      "       13975       0.50      0.67      0.57         6\n",
      "       13976       1.00      0.50      0.67        12\n",
      "       13977       0.75      0.38      0.50         8\n",
      "       13978       0.00      0.00      0.00         1\n",
      "       13982       0.61      0.76      0.68        88\n",
      "       13986       0.89      0.73      0.80        11\n",
      "       13988       0.00      0.00      0.00         1\n",
      "       13989       0.75      0.48      0.59        25\n",
      "       13990       1.00      0.18      0.31        11\n",
      "       13994       0.80      0.57      0.67         7\n",
      "       13995       0.95      0.99      0.97       342\n",
      "       13997       1.00      0.08      0.15        12\n",
      "       14000       0.00      0.00      0.00        15\n",
      "       14003       0.89      0.91      0.90       157\n",
      "       14005       0.00      0.00      0.00         8\n",
      "       14007       0.73      0.62      0.67       245\n",
      "       14008       0.73      0.89      0.80        27\n",
      "       14011       0.76      0.73      0.74        22\n",
      "       14014       0.67      0.79      0.72       150\n",
      "       14017       1.00      0.13      0.24        15\n",
      "       14018       0.80      0.50      0.62         8\n",
      "       14019       0.74      0.79      0.76        33\n",
      "       14023       1.00      0.14      0.25         7\n",
      "       14024       0.78      0.67      0.72        21\n",
      "       14025       0.00      0.00      0.00         2\n",
      "       14028       1.00      0.53      0.70        15\n",
      "       14030       0.73      0.90      0.81       116\n",
      "       14032       0.00      0.00      0.00         4\n",
      "       14033       0.00      0.00      0.00         5\n",
      "       14034       0.77      0.95      0.85       243\n",
      "       14036       0.98      0.95      0.96        58\n",
      "       14037       0.95      0.95      0.95        63\n",
      "       14038       1.00      0.40      0.57        10\n",
      "       14042       0.00      0.00      0.00         4\n",
      "       14046       0.00      0.00      0.00         1\n",
      "       14048       1.00      0.40      0.57         5\n",
      "       14050       0.73      0.86      0.79       111\n",
      "       14061       0.00      0.00      0.00         6\n",
      "       14064       0.75      0.50      0.60        12\n",
      "       14065       0.80      0.50      0.62        32\n",
      "       14066       0.00      0.00      0.00         3\n",
      "       14067       0.00      0.00      0.00         6\n",
      "       14069       1.00      0.33      0.50         3\n",
      "       14071       0.00      0.00      0.00         2\n",
      "       14075       1.00      0.88      0.94        50\n",
      "       14076       0.91      0.41      0.57        75\n",
      "       14079       1.00      0.80      0.89         5\n",
      "       14081       0.90      0.86      0.88        22\n",
      "       14088       0.00      0.00      0.00         3\n",
      "       14093       0.50      0.56      0.53         9\n",
      "       14095       0.83      0.50      0.62        20\n",
      "       14096       0.00      0.00      0.00         7\n",
      "       14097       0.00      0.00      0.00        15\n",
      "       14099       0.60      0.54      0.57       138\n",
      "       14103       0.84      0.82      0.83        56\n",
      "       14105       0.00      0.00      0.00         7\n",
      "       14108       0.00      0.00      0.00         6\n",
      "       14109       0.00      0.00      0.00         3\n",
      "       14110       0.00      0.00      0.00         7\n",
      "       14111       0.89      0.90      0.90        63\n",
      "       14113       0.86      0.81      0.83        62\n",
      "       14117       0.00      0.00      0.00         5\n",
      "       14123       0.81      0.81      0.81        32\n",
      "       14125       0.89      0.91      0.90       395\n",
      "       14133       0.53      0.85      0.66        27\n",
      "       14134       0.00      0.00      0.00         2\n",
      "       14137       0.00      0.00      0.00         2\n",
      "       14140       0.00      0.00      0.00         5\n",
      "       14141       0.94      0.84      0.89        19\n",
      "       14142       0.00      0.00      0.00         1\n",
      "       14143       1.00      0.29      0.44         7\n",
      "       14149       0.00      0.00      0.00         9\n",
      "       14153       0.74      0.88      0.81        26\n",
      "       14158       0.64      0.61      0.62        49\n",
      "       14160       0.00      0.00      0.00        11\n",
      "       14161       0.50      0.47      0.49        55\n",
      "       14165       0.00      0.00      0.00         2\n",
      "       14167       0.00      0.00      0.00         2\n",
      "       14171       0.60      0.62      0.61        78\n",
      "       14172       0.86      0.55      0.67        11\n",
      "       14182       0.00      0.00      0.00         3\n",
      "       14186       0.80      0.42      0.55        19\n",
      "       14191       0.60      0.76      0.67        33\n",
      "       14196       1.00      1.00      1.00         6\n",
      "       14200       0.00      0.00      0.00         1\n",
      "       14201       0.00      0.00      0.00         1\n",
      "       14202       0.00      0.00      0.00         2\n",
      "       14205       0.71      0.71      0.71         7\n",
      "       14207       0.00      0.00      0.00         4\n",
      "       14216       0.61      0.81      0.69        42\n",
      "       14219       0.86      0.53      0.66        36\n",
      "       14220       0.82      0.92      0.86       153\n",
      "       14221       0.96      1.00      0.98        51\n",
      "       14225       0.76      0.92      0.83       179\n",
      "       14226       0.00      0.00      0.00         6\n",
      "       14227       0.00      0.00      0.00         1\n",
      "       14230       0.00      0.00      0.00         3\n",
      "       14233       0.94      0.98      0.96       582\n",
      "       14235       0.96      0.98      0.97        44\n",
      "       14238       0.00      0.00      0.00         4\n",
      "       14241       0.84      0.99      0.91       377\n",
      "       14242       0.72      0.96      0.82       317\n",
      "       14243       0.00      0.00      0.00         4\n",
      "       14244       0.93      0.74      0.82        19\n",
      "       14245       0.80      0.67      0.73        12\n",
      "       14248       0.00      0.00      0.00         2\n",
      "       14251       0.95      0.99      0.97       143\n",
      "       14255       0.94      0.59      0.73        27\n",
      "       14256       0.00      0.00      0.00         3\n",
      "       14258       0.92      1.00      0.96        11\n",
      "       14262       1.00      1.00      1.00        13\n",
      "       14263       0.00      0.00      0.00         9\n",
      "       14265       1.00      0.86      0.93        29\n",
      "       14266       0.90      0.90      0.90        20\n",
      "       14267       0.73      0.73      0.73        11\n",
      "       14269       0.00      0.00      0.00         7\n",
      "       14271       0.83      0.31      0.45        16\n",
      "       14274       0.79      0.77      0.78       191\n",
      "       14276       0.78      0.96      0.86       141\n",
      "       14277       1.00      0.30      0.46        10\n",
      "       14278       0.91      0.82      0.86        49\n",
      "       14279       0.82      0.93      0.87        94\n",
      "       14281       0.74      0.59      0.65        58\n",
      "       14282       0.78      0.83      0.80        42\n",
      "       14365       1.00      0.32      0.49        31\n",
      "       14366       0.50      0.17      0.25         6\n",
      "       14367       1.00      0.05      0.09        21\n",
      "       14379       0.55      0.50      0.52        22\n",
      "       14398       1.00      0.60      0.75         5\n",
      "       14432       0.00      0.00      0.00         6\n",
      "       14433       0.78      0.87      0.82        52\n",
      "       14434       0.88      0.91      0.90        80\n",
      "       14500       0.62      0.62      0.62         8\n",
      "       14501       1.00      0.22      0.36         9\n",
      "       14502       1.00      0.38      0.56        13\n",
      "       14503       0.93      0.64      0.76        22\n",
      "       14538       0.89      0.80      0.84        20\n",
      "       14539       0.95      0.81      0.88        26\n",
      "       14540       1.00      0.62      0.77         8\n",
      "       14543       1.00      1.00      1.00         4\n",
      "       14546       0.70      0.57      0.63        37\n",
      "       14547       0.00      0.00      0.00         4\n",
      "       14548       0.00      0.00      0.00        14\n",
      "       14549       0.64      0.36      0.46        39\n",
      "       14550       0.00      0.00      0.00         4\n",
      "       14551       0.58      0.44      0.50        16\n",
      "       14552       1.00      0.50      0.67         4\n",
      "       14553       1.00      0.50      0.67         4\n",
      "       14557       0.00      0.00      0.00         1\n",
      "       14559       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.81     56691\n",
      "   macro avg       0.57      0.46      0.48     56691\n",
      "weighted avg       0.80      0.81      0.79     56691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artem/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artem/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_cat,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc224ec9-f2a5-486b-90f8-f312d802287b",
   "metadata": {},
   "source": [
    "# Calculation of hierarchical metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d62a167-f2c3-4e6b-8af2-25d78113ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(preds,columns = ['Predicted Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59fbafbb-8b31-4692-84dc-0d8f379c5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Predicted Path'] = results['Predicted Label'].apply(get_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd0eb76c-546c-4344-82db-7861e4ddfa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['True Label'] = y_val_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ce28081-bf52-446b-8550-a02721673f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['True Path'] = results['True Label'].apply(get_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "231e36de-f5c3-4b16-956a-a5e1d035fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Predicted Path</th>\n",
       "      <th>True Label</th>\n",
       "      <th>True Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12171</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "      <td>12171</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13495</td>\n",
       "      <td>[Все категории, Товары для дома, Товары для пр...</td>\n",
       "      <td>13495</td>\n",
       "      <td>[Все категории, Товары для дома, Товары для пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13408</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "      <td>13408</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12128</td>\n",
       "      <td>[Все категории, Одежда, Женская одежда, Шорты ...</td>\n",
       "      <td>12128</td>\n",
       "      <td>[Все категории, Одежда, Женская одежда, Шорты ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12049</td>\n",
       "      <td>[Все категории, Электроника, Аксессуары для эл...</td>\n",
       "      <td>12171</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56686</th>\n",
       "      <td>12781</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "      <td>12781</td>\n",
       "      <td>[Все категории, Электроника, Смартфоны и телеф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56687</th>\n",
       "      <td>14434</td>\n",
       "      <td>[Все категории, Красота, Парфюмерия, Миниатюры...</td>\n",
       "      <td>14434</td>\n",
       "      <td>[Все категории, Красота, Парфюмерия, Миниатюры...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56688</th>\n",
       "      <td>13143</td>\n",
       "      <td>[Все категории, Одежда, Женская одежда, Колгот...</td>\n",
       "      <td>13143</td>\n",
       "      <td>[Все категории, Одежда, Женская одежда, Колгот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56689</th>\n",
       "      <td>2895</td>\n",
       "      <td>[Все категории, Товары для дома, Мебель, Пуфик...</td>\n",
       "      <td>2895</td>\n",
       "      <td>[Все категории, Товары для дома, Мебель, Пуфик...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56690</th>\n",
       "      <td>12297</td>\n",
       "      <td>[Все категории, Аксессуары, Аксессуары для мал...</td>\n",
       "      <td>12297</td>\n",
       "      <td>[Все категории, Аксессуары, Аксессуары для мал...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56691 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted Label                                     Predicted Path  \\\n",
       "0                12171  [Все категории, Электроника, Смартфоны и телеф...   \n",
       "1                13495  [Все категории, Товары для дома, Товары для пр...   \n",
       "2                13408  [Все категории, Электроника, Смартфоны и телеф...   \n",
       "3                12128  [Все категории, Одежда, Женская одежда, Шорты ...   \n",
       "4                12049  [Все категории, Электроника, Аксессуары для эл...   \n",
       "...                ...                                                ...   \n",
       "56686            12781  [Все категории, Электроника, Смартфоны и телеф...   \n",
       "56687            14434  [Все категории, Красота, Парфюмерия, Миниатюры...   \n",
       "56688            13143  [Все категории, Одежда, Женская одежда, Колгот...   \n",
       "56689             2895  [Все категории, Товары для дома, Мебель, Пуфик...   \n",
       "56690            12297  [Все категории, Аксессуары, Аксессуары для мал...   \n",
       "\n",
       "       True Label                                          True Path  \n",
       "0           12171  [Все категории, Электроника, Смартфоны и телеф...  \n",
       "1           13495  [Все категории, Товары для дома, Товары для пр...  \n",
       "2           13408  [Все категории, Электроника, Смартфоны и телеф...  \n",
       "3           12128  [Все категории, Одежда, Женская одежда, Шорты ...  \n",
       "4           12171  [Все категории, Электроника, Смартфоны и телеф...  \n",
       "...           ...                                                ...  \n",
       "56686       12781  [Все категории, Электроника, Смартфоны и телеф...  \n",
       "56687       14434  [Все категории, Красота, Парфюмерия, Миниатюры...  \n",
       "56688       13143  [Все категории, Одежда, Женская одежда, Колгот...  \n",
       "56689        2895  [Все категории, Товары для дома, Мебель, Пуфик...  \n",
       "56690       12297  [Все категории, Аксессуары, Аксессуары для мал...  \n",
       "\n",
       "[56691 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f335da38-fe65-4008-a234-c4778e9b2250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Все категории</td>\n",
       "      <td>0</td>\n",
       "      <td>[Все категории]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Урбеч</td>\n",
       "      <td>1913</td>\n",
       "      <td>[Все категории, Продукты питания, Здоровое пит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Варенье и джемы</td>\n",
       "      <td>328</td>\n",
       "      <td>[Все категории, Продукты питания, Мед, варенье...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Сухие завтраки</td>\n",
       "      <td>2475</td>\n",
       "      <td>[Все категории, Продукты питания, Бакалея, Сух...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Масла</td>\n",
       "      <td>2475</td>\n",
       "      <td>[Все категории, Продукты питания, Бакалея, Масла]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>Насадки и запчасти</td>\n",
       "      <td>11691</td>\n",
       "      <td>[Все категории, Бытовая техника, Товары для ку...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14556</th>\n",
       "      <td>Швейные машины</td>\n",
       "      <td>10062</td>\n",
       "      <td>[Все категории, Бытовая техника, Техника для д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14557</th>\n",
       "      <td>Матрасы</td>\n",
       "      <td>2894</td>\n",
       "      <td>[Все категории, Товары для дома, Мебель, Матрасы]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14558</th>\n",
       "      <td>Ледянки и тюбинги</td>\n",
       "      <td>10092</td>\n",
       "      <td>[Все категории, Спорт и отдых, Зимний спорт, Л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14559</th>\n",
       "      <td>Аксессуары для сушки белья</td>\n",
       "      <td>12823</td>\n",
       "      <td>[Все категории, Товары для дома, Хозяйственные...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  parent_id  \\\n",
       "id                                             \n",
       "1                   Все категории          0   \n",
       "114                         Урбеч       1913   \n",
       "115               Варенье и джемы        328   \n",
       "128                Сухие завтраки       2475   \n",
       "131                         Масла       2475   \n",
       "...                           ...        ...   \n",
       "14555          Насадки и запчасти      11691   \n",
       "14556              Швейные машины      10062   \n",
       "14557                     Матрасы       2894   \n",
       "14558           Ледянки и тюбинги      10092   \n",
       "14559  Аксессуары для сушки белья      12823   \n",
       "\n",
       "                                                    path  \n",
       "id                                                        \n",
       "1                                        [Все категории]  \n",
       "114    [Все категории, Продукты питания, Здоровое пит...  \n",
       "115    [Все категории, Продукты питания, Мед, варенье...  \n",
       "128    [Все категории, Продукты питания, Бакалея, Сух...  \n",
       "131    [Все категории, Продукты питания, Бакалея, Масла]  \n",
       "...                                                  ...  \n",
       "14555  [Все категории, Бытовая техника, Товары для ку...  \n",
       "14556  [Все категории, Бытовая техника, Техника для д...  \n",
       "14557  [Все категории, Товары для дома, Мебель, Матрасы]  \n",
       "14558  [Все категории, Спорт и отдых, Зимний спорт, Л...  \n",
       "14559  [Все категории, Товары для дома, Хозяйственные...  \n",
       "\n",
       "[3370 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = df_categories_tree.set_index('id')\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73b67be3-e4ea-419b-9bbb-e580e4899931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hierarchical metrics for every category_id\n",
    "cat_ids = list(results.groupby('True Label').groups.keys())\n",
    "\n",
    "dict_with_f1 = {}\n",
    "\n",
    "for cat_id in cat_ids:\n",
    "    \n",
    "    cat_id_group_df = results[(results['True Label'] == cat_id) | (results['Predicted Label'] == cat_id)].copy()\n",
    "    \n",
    "    true_path_set = set(categories['path'].loc[cat_id])\n",
    "    func_1 = lambda v: len(set(v).intersection(true_path_set))\n",
    "    func_2 = lambda t, p: len(set(t).intersection(set(p)))\n",
    "    \n",
    "    cat_id_group_df['|Ti|'] = cat_id_group_df['True Path'].apply(func_1)\n",
    "    cat_id_group_df['|Pi|'] = cat_id_group_df['Predicted Path'].apply(func_1)\n",
    "    cat_id_group_df['|Pi Ω Ti|'] = cat_id_group_df[['True Path', 'Predicted Path']].apply(lambda x: func_2(*x), \n",
    "                                                                                          axis=1)\n",
    "    \n",
    "    hP = (cat_id_group_df['|Pi Ω Ti|'].sum()) / (cat_id_group_df['|Pi|'].sum())\n",
    "    hR = (cat_id_group_df['|Pi Ω Ti|'].sum()) / (cat_id_group_df['|Ti|'].sum())\n",
    "    hF = (2*hP*hR)/(hP+hR)\n",
    "    \n",
    "    dict_with_f1[cat_id] = hF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a7445e0-a243-4747-844e-987cedc0cf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1146"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_with_f1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82ddcd2d-d52e-4952-aab1-111d4c4f1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1_per_category = pd.DataFrame.from_dict({ \"category_id\": list(dict_with_f1.keys()),\n",
    "  \"hF1\": list(dict_with_f1.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5f76937-801e-41ce-9ff0-659fa34cf94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>hF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2598</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2599</td>\n",
       "      <td>0.980344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601</td>\n",
       "      <td>0.841379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2602</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>14551</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>14552</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>14553</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>14557</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>14559</td>\n",
       "      <td>0.762887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category_id       hF1\n",
       "0            2598  0.888889\n",
       "1            2599  0.980344\n",
       "2            2600  0.936170\n",
       "3            2601  0.841379\n",
       "4            2602  0.952381\n",
       "...           ...       ...\n",
       "1141        14551  0.816901\n",
       "1142        14552  0.829268\n",
       "1143        14553  0.933333\n",
       "1144        14557  0.666667\n",
       "1145        14559  0.762887\n",
       "\n",
       "[1146 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf1_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5722aec1-dece-4b45-a91b-3c941e7d9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_category = results.groupby('True Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41abcfe9-0d92-4592-94a2-71706446bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_category = items_per_category.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f13a0fe1-6f00-47a6-b663-48e1972f34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_cal_of_weighted_hF1 = pd.merge(hf1_per_category, items_per_category[['True Label','Predicted Label']], how = 'left', \n",
    "         left_on = 'category_id', right_on = 'True Label').drop('True Label',axis=1)\n",
    "df_for_cal_of_weighted_hF1.rename(columns = {'Predicted Label':'count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9670fcb-c6b5-4b97-a205-c8059d83958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>hF1</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2598</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2599</td>\n",
       "      <td>0.980344</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2602</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>14551</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>14552</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>14553</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>14557</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>14559</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category_id       hF1  count\n",
       "0            2598  0.888889      1\n",
       "1            2599  0.980344     77\n",
       "2            2600  0.936170     10\n",
       "3            2601  0.841379     64\n",
       "4            2602  0.952381     27\n",
       "...           ...       ...    ...\n",
       "1141        14551  0.816901     16\n",
       "1142        14552  0.829268      4\n",
       "1143        14553  0.933333      4\n",
       "1144        14557  0.666667      1\n",
       "1145        14559  0.762887     10\n",
       "\n",
       "[1146 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_cal_of_weighted_hF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f677bd7b-2955-4e21-ac68-c2d2c8e8e28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted hierarchical F1 is equal to 92.42%\n"
     ]
    }
   ],
   "source": [
    "weighted_hF1 = (df_for_cal_of_weighted_hF1['count'] * df_for_cal_of_weighted_hF1['hF1']).sum() / len(results)\n",
    "print('Weighted hierarchical F1 is equal to', f'{weighted_hF1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b494df-f058-48d0-a700-95e7dfacbe86",
   "metadata": {},
   "source": [
    "# Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6213e38b-ff2c-4e54-a757-442167b77518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['short_description'] = df_test['short_description'].fillna(\"\")\n",
    "df_test['title+short_description'] = df_test['title'] + df_test['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "922c100b-ed9f-4080-82b1-e31588b3c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['title+short_description'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c02a7b8-2f7b-4e99-b1fe-bdfdee03faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6eb29c67-d5df-4f73-b192-9b9dfd7c0aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70864x127245 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 568452 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "490d5627-7568-44f1-9b9f-7988aa2c5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bc472ed-834c-481e-b200-ce01c96c2501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 130,  242,  809, ...,  820,  721, 1098])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fdd9a4f-d000-4cc1-9f12-e4a69fe5cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "for pred in predictions:\n",
    "    final_predictions.append(cat_ids_list[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df18d695-b1a2-4793-bda6-16f77ebcf04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predicted_category_id'] = final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14d9512a-a42c-4a9a-b926-4e52a3b7a236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070974</td>\n",
       "      <td>11574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450413</td>\n",
       "      <td>11878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126857</td>\n",
       "      <td>13299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577569</td>\n",
       "      <td>13061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>869328</td>\n",
       "      <td>12813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70859</th>\n",
       "      <td>967535</td>\n",
       "      <td>13143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70860</th>\n",
       "      <td>1488636</td>\n",
       "      <td>12350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70861</th>\n",
       "      <td>827510</td>\n",
       "      <td>13324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70862</th>\n",
       "      <td>529244</td>\n",
       "      <td>13069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70863</th>\n",
       "      <td>1400885</td>\n",
       "      <td>14034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  predicted_category_id\n",
       "0      1070974                  11574\n",
       "1       450413                  11878\n",
       "2       126857                  13299\n",
       "3      1577569                  13061\n",
       "4       869328                  12813\n",
       "...        ...                    ...\n",
       "70859   967535                  13143\n",
       "70860  1488636                  12350\n",
       "70861   827510                  13324\n",
       "70862   529244                  13069\n",
       "70863  1400885                  14034\n",
       "\n",
       "[70864 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table = df_test[['id','predicted_category_id']]\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "429bca2f-3a77-491c-8aad-6c021fff679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.to_parquet('result.parquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89703274-e207-4c8f-bce0-f191c2ba13c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070974</td>\n",
       "      <td>11574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450413</td>\n",
       "      <td>11878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126857</td>\n",
       "      <td>13299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577569</td>\n",
       "      <td>13061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>869328</td>\n",
       "      <td>12813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70859</th>\n",
       "      <td>967535</td>\n",
       "      <td>13143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70860</th>\n",
       "      <td>1488636</td>\n",
       "      <td>12350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70861</th>\n",
       "      <td>827510</td>\n",
       "      <td>13324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70862</th>\n",
       "      <td>529244</td>\n",
       "      <td>13069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70863</th>\n",
       "      <td>1400885</td>\n",
       "      <td>14034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  predicted_category_id\n",
       "0      1070974                  11574\n",
       "1       450413                  11878\n",
       "2       126857                  13299\n",
       "3      1577569                  13061\n",
       "4       869328                  12813\n",
       "...        ...                    ...\n",
       "70859   967535                  13143\n",
       "70860  1488636                  12350\n",
       "70861   827510                  13324\n",
       "70862   529244                  13069\n",
       "70863  1400885                  14034\n",
       "\n",
       "[70864 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('result.parquet')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638dd1b5-2448-4223-bd3e-71f6b8064c67",
   "metadata": {},
   "source": [
    "# TRANSFORMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c12ee9-697f-4edb-b68f-6e4367acda5b",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26d52e82-893a-40a2-b396-a897aea07e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(zip(X_train, y_train), columns=[X_train.name, \"labels\"])\n",
    "val = pd.DataFrame(zip(X_val, y_val), columns=[X_val.name, \"labels\"])\n",
    "\n",
    "# Create a DatasetDict object and add to it train, validation and test datasets \n",
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = Dataset.from_pandas(train)\n",
    "dataset[\"validation\"] = Dataset.from_pandas(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c464ae0-1127-4e1b-921b-bea0bfddd127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title+short_description', 'labels'],\n",
       "        num_rows: 226761\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title+short_description', 'labels'],\n",
       "        num_rows: 56691\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d5753-3852-4e80-8fc9-863b2dcc9760",
   "metadata": {},
   "source": [
    "## Tokenization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c8ee879-9f0a-4d9f-99e1-492d2b507a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"bert-base-multilingual-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "653416ad-1805-4390-81c7-ca80861b29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer associated with a pretrained model. We use BERT base multilingual model (uncased)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39b21411-182c-4fa8-b784-6eb010f372e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the model's maximum content size\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af3ea10c-0859-408b-8750-cb45cfab1824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the names of the fields that the model expects in its forward pass\n",
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d762ac23-0d79-49e9-97b8-a50e694bab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that applies the tokenizer to a batch of examples,padding=True will pad the examples with \n",
    "# zeros to the size of the longest one in a batch, and truncation=True will truncate the examples to the model’s \n",
    "# maximum context size\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"title+short_description\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77f7e78e-44af-4321-9242-c9de0a94dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be717d42a7fd4249b0a10fb73c4b97bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594b8d53fe5443ebac85e8535dff6210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can apply this function across all dataset\n",
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff010a7b-dcb9-4014-8c39-867f4ccf477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title+short_description', 'labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# This operation has added new input_ids, attention_mask and token_type_ids columns to the dataset\n",
    "\n",
    "print(dataset_encoded[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464efdf6-7fc5-474a-972a-8026394887b3",
   "metadata": {},
   "source": [
    "## Training a Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249907d-f91b-47f6-b8d3-293467241015",
   "metadata": {},
   "source": [
    "We train a model with fine-tuning: end-to-end, which also updates the parameters of the pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1339578-0310-46a4-9c41-2330844f4d37",
   "metadata": {},
   "source": [
    "### Fine-Tuning Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4257ff3-dab4-49dc-9b4b-8ffbad02bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfb3e166-5908-407f-ae26-de37a053ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 1231\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained('bert-base-multilingual-uncased', num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdd25b62-db73-4c06-b97e-b1b5d312ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will monitor the F1-score and the accuracy of the model during training. \n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfd9c5c1-2e6e-417b-8d9d-b77f3e977454",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "logging_steps = len(dataset_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-items-classification\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=1,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  lr_scheduler_type=\"linear\",\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"eval_loss\",\n",
    "                                  greater_is_better=False,\n",
    "                                  weight_decay=0.01,\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  report_to=\"none\",\n",
    "                                  push_to_hub=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb5cd0e2-8427-4d86-b493-92cea65e1da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3544' max='3544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3544/3544 46:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.192100</td>\n",
       "      <td>2.133701</td>\n",
       "      <td>0.661675</td>\n",
       "      <td>0.581314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3544, training_loss=3.191546302112177, metrics={'train_runtime': 2776.7598, 'train_samples_per_second': 81.664, 'train_steps_per_second': 1.276, 'total_flos': 2.1913739902746756e+16, 'train_loss': 3.191546302112177, 'epoch': 1.0})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=dataset_encoded[\"train\"],\n",
    "                  eval_dataset=dataset_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96616819-93b4-497c-9ba0-3f6bd8f3439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='886' max='886' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [886/886 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_output = trainer.predict(dataset_encoded['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b41b1d4f-7ae3-4006-9daf-d85571bbf00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.1337006092071533,\n",
       " 'test_accuracy': 0.6616746926319874,\n",
       " 'test_f1': 0.5813144041747497,\n",
       " 'test_runtime': 167.946,\n",
       " 'test_samples_per_second': 337.555,\n",
       " 'test_steps_per_second': 5.276}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb8b12-5b6b-4421-9511-8d70892b12fe",
   "metadata": {},
   "source": [
    "Due to limited compute power, only one training epoch was completed. Only 1 epoch of training of the transformer-based model resulted in a worse result in terms of F1 score compared to the first approach (Tf-idf + Miltinomial Logistic Regression). Therefore, it was decided to choose the first approach for predic of the test set.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
